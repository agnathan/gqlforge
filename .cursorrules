# Cursor Rules for gqlforge

## Project Overview

This is a TypeScript library for working with GraphQL schemas using a context-free grammar (CFG) representation. The project uses a plugin architecture with parsers, transformers, and generators.

## Reference Documentation

**CRITICAL: Always use `src/grammar.ts` as the authoritative reference** when implementing GraphQL-related functionality. This file contains the complete GraphQL Grammar Specification (September 2025 Edition) and defines:

- All grammar element types (Terminal, NonTerminal, Sequence, OneOf, Optional, List)
- The complete GraphQL grammar structure following the specification
- Helper functions for constructing grammar elements
- The canonical `GraphQLGrammar` object

When implementing parsers, generators, or transformers:
1. **Always reference `src/grammar.ts`** to understand the grammar structure
2. Follow the specification sections (3.3 Schema, 3.5 Scalars, 3.6 Objects, etc.)
3. Use the helper functions (`T()`, `NT()`, `Seq()`, `Or()`, `Opt()`, `Lst()`) when constructing grammar elements
4. Ensure implementations match the grammar structure defined in `src/grammar.ts`

## Testing Architecture

### Fixture-Based Testing

All tests use fixture-based testing organized by plugin type:

```
tests/
  fixtures/
    parsers/{parser-name}/
      valid/          # Valid input schemas
      invalid/        # Invalid input schemas
      expected/       # Expected grammar outputs
      validation/    # Expected validation results
      linting/        # Expected linting results
    
    transformers/{transformer-name}/
      input/          # Input schemas/grammars
      expected/       # Expected outputs
      config/         # Transformer options
      validation/     # Expected validation results
      linting/        # Expected linting results
    
    generators/{generator-name}/
      input/          # Input grammars
      expected/       # Expected outputs
      config/         # Generator options
      validation/     # Expected validation results
      linting/        # Expected linting results
```

### Test Organization

Tests are organized by plugin type, mirroring the fixture structure. For plugins with many tests, split into multiple files by grammar section or feature area:

```
tests/
  parsers/
    {parser-name}.test.ts                    # Main test file (if small)
    {parser-name}.{section}.test.ts         # Section-specific tests (if large)
  transformers/
    {transformer-name}.test.ts
  generators/
    {generator-name}.test.ts                 # Main test file (if small)
    {generator-name}.{section}.test.ts      # Section-specific tests (if large)
```

**Splitting Guidelines:**
- **Keep files under ~300-400 lines** for optimal AI agent efficiency
- **Split by grammar section** (e.g., `graphql-sdl.schema.test.ts`, `graphql-sdl.scalars.test.ts`)
- **Split by feature area** (e.g., `graphql-sdl.config.test.ts` for configuration tests)
- **Maintain consistent structure** - each file should have the same imports and setup
- **Use descriptive file names** that match the grammar section or feature being tested

**Example Structure for Large Test Suites:**
```
tests/generators/graphql-sdl/
  graphql-sdl.test.ts                        # Main file with shared setup
  graphql-sdl.schema.test.ts                 # 3.3 Schema Definition tests
  graphql-sdl.scalars.test.ts                # 3.5 Scalar Type tests
  graphql-sdl.objects.test.ts                # 3.6 Object Type tests
  graphql-sdl.interfaces.test.ts             # 3.7 Interface Type tests
  graphql-sdl.config.test.ts                 # Configuration option tests
  graphql-sdl.lexical-tokens.test.ts         # C.1-C.3 Lexical Tokens tests
```

**Benefits of Splitting:**
- **AI Agent Efficiency**: Smaller files = faster context loading and better focus
- **Maintainability**: Easier to find and modify specific test sections
- **Parallel Development**: Multiple developers can work on different sections simultaneously
- **Clear Organization**: Each file has a single, clear responsibility
- **Reduced Cognitive Load**: Easier to understand and reason about smaller files

### Critical Testing Rules

1. **ALL tests that generate GraphQL MUST validate and lint the output**
   - Use `expectValidGraphQL()` helper from `tests/helpers/schema-validator.ts`
   - This ensures generated GraphQL is both valid (spec-compliant) and follows best practices
   - Tests will fail if validation/linting errors occur

2. **Fixture Loading**
   - Use `loadParserFixtures()`, `loadTransformerFixtures()`, or `loadGeneratorFixtures()`
   - Import from `tests/helpers/fixtures.ts`
   - Fixtures are organized by plugin name

3. **Validation Requirements**
   - Generator tests: Always validate generated GraphQL
   - Transformer tests: Validate GraphQL generated from transformed grammar
   - Parser tests: Validate GraphQL generated from parsed grammar (round-trip)

4. **Error Capture for Regression**
   - Use `captureValidationErrors()` to save validation results as fixtures
   - Store expected validation/linting results in `validation/` and `linting/` directories
   - Compare actual vs expected using `validateAndLintGraphQL()` with fixture path

### Helper Functions

**Fixture Loading:**
```typescript
import { loadGeneratorFixtures } from '../helpers/fixtures';
const fixtures = loadGeneratorFixtures('json');
const input = fixtures.input('simple-grammar.json');
```

**GraphQL Validation:**
```typescript
import { expectValidGraphQL } from '../helpers/schema-validator';

// Required: Validate generated GraphQL
await expectValidGraphQL(generatedSDL, undefined, {
  failOnWarnings: false,  // Warnings OK, errors not OK
});

// With expected results fixture:
await expectValidGraphQL(
  generatedSDL,
  'generators/json/validation/simple-valid.json',
  { acceptableWarnings: ['@graphql-eslint/require-description'] }
);
```

**Validation Result Capture:**
```typescript
import { captureValidationErrors } from '../helpers/schema-validator';

const results = await captureValidationErrors(
  schemaSDL,
  'generators/json/validation/simple-valid.json',
  { updateFixture: true, acceptableWarnings: [...] }
);
```

### Test Patterns

**Generator Test Pattern:**
```typescript
describe('{generator-name} generator', () => {
  const fixtures = loadGeneratorFixtures('{generator-name}');
  
  it('generates valid GraphQL', async () => {
    const input = fixtures.input('simple-grammar.json');
    const output = generator.generate(input);
    
    // REQUIRED: Validate generated GraphQL
    await expectValidGraphQL(output, undefined, {
      failOnWarnings: false,
    });
  });
});
```

**Transformer Test Pattern:**
```typescript
describe('{transformer-name} transformer', () => {
  const fixtures = loadTransformerFixtures('{transformer-name}');
  
  it('transforms and generates valid GraphQL', async () => {
    const options = fixtures.config('options.json');
    const result = registry.transform(grammar, ['{transformer-name}'], {
      '{transformer-name}': options,
    });
    
    // Generate GraphQL from transformed grammar
    const generatedSDL = registry.generate(result.grammar, 'graphql-sdl');
    
    // REQUIRED: Validate generated GraphQL
    await expectValidGraphQL(generatedSDL.output as string, undefined, {
      failOnWarnings: false,
    });
  });
});
```

**Parser Test Pattern:**
```typescript
describe('{parser-name} parser', () => {
  const fixtures = loadParserFixtures('{parser-name}');
  
  it('parses and generates valid GraphQL', async () => {
    const schemaSDL = fixtures.valid('simple.graphql');
    const parsedGrammar = parser.parse(schemaSDL);
    
    // Generate GraphQL from parsed grammar
    const generatedSDL = registry.generate(parsedGrammar, 'graphql-sdl');
    
    // REQUIRED: Validate generated GraphQL (round-trip validation)
    await expectValidGraphQL(generatedSDL.output as string, undefined, {
      failOnWarnings: false,
    });
  });
});
```

### Validation Result Fixture Format

```json
{
  "isValid": true,
  "errors": [],
  "warnings": [
    {
      "message": "Type 'User' is missing a description",
      "line": 2,
      "ruleId": "@graphql-eslint/require-description"
    }
  ],
  "acceptableWarnings": ["@graphql-eslint/require-description"]
}
```

### Best Practices

1. **Always validate GraphQL outputs** - No exceptions
2. **Use fixtures for test data** - Don't inline test data
3. **Organize by plugin** - Keep fixtures and tests together by plugin type
4. **Capture validation results** - Store expected results for regression testing
5. **Document acceptable warnings** - Use `acceptableWarnings` in fixtures
6. **Fail on errors, not warnings** - Use `failOnWarnings: false` unless specifically testing for warnings
7. **Update fixtures intentionally** - Use `updateFixture: true` only when intentionally updating expected results

### Adding New Tests

When adding a new test:

1. Create fixtures in appropriate plugin directory
2. Use fixture loading helpers
3. **Always validate GraphQL outputs** using `expectValidGraphQL()`
4. Store expected validation results if testing specific error scenarios
5. Follow the test patterns above

### Running Tests

```bash
npm test                    # Run all tests
npm test -- --run          # Run once (no watch)
npm test -- {pattern}      # Run specific tests
npm test -- --ui           # UI mode
npm test -- -t {TEST_ID}   # Run test by ID (e.g., GEN-GSDL-001)
```

### Test IDs

Every test has a unique ID for easy reference in documentation and when communicating with AI agents.

**Format**: `{TYPE}-{PLUGIN}-{NUMBER}`
- **TYPE**: `GEN` (generator), `TRANS` (transformer), `PARSE` (parser), `VALID` (validation)
- **PLUGIN**: Short plugin identifier (e.g., `GSDL` for graphql-sdl, `AF` for add-field)
- **NUMBER**: Sequential test number within the plugin (001, 002, etc.)

**Examples**:
- `GEN-GSDL-001`: Generator graphql-sdl test #1 - "generates schema definition with root operation types"
- `TRANS-AF-001`: Transformer add-field test #1 - "adds email field to User type"
- `PARSE-GSDL-001`: Parser graphql-sdl test #1 - "parses simple schema"

**Usage**:
- Reference tests in documentation: "See test `GEN-GSDL-001` for schema definition generation"
- Run specific test: `npm test -- -t GEN-GSDL-001`
- Communicate with AI agents: "Fix the issue in test `GEN-GSDL-001`"

Test IDs are registered in `tests/helpers/test-ids.ts` and appear in test names: `[GEN-GSDL-001] generates schema definition...`

### Test Reporting

All tests automatically generate detailed reports in `test-reports/{datetime}/{test-file}/{test-id}-{status}.json`.

**Report Structure:**
- `test-reports/` - Root directory (gitignored)
- `{datetime}/` - Directory named with ISO datetime (e.g., `2025-12-07T21-04-32`)
- `{test-file}/` - Directory named after test file (e.g., `graphql-sdl`)
- `{test-id}-{status}.json` - Report file (e.g., `GEN-GSDL-001-PASSED.json`)

**Report Contents:**
- Test ID and description
- Status (PASSED/FAILED)
- Timestamp
- Test file path
- Input data
- Expected output
- Actual output
- Errors (if failed)
- Validation errors and warnings
- Validation result summary

**Usage:**
```typescript
import { initTestReport, reportTestPassed, reportTestFailed } from "../helpers/report-test";

it(`[${TEST_ID}] test description`, async () => {
  const input = fixtures.input("input.json");
  const expected = fixtures.expected("expected.graphql");
  
  initTestReport({
    testId: TEST_ID,
    description: "test description",
    input,
    expectedOutput: expected,
  });
  
  const output = generator.generate(input);
  
  try {
    const validationResult = await expectValidGraphQL(output, undefined, {
      expectedFixture: expected,
      testId: TEST_ID,
    });
    
    reportTestPassed({
      testId: TEST_ID,
      description: "test description",
      input,
      expectedOutput: expected,
      actualOutput: output,
      validationResult,
    });
  } catch (error) {
    reportTestFailed(
      {
        testId: TEST_ID,
        description: "test description",
        input,
        expectedOutput: expected,
        actualOutput: output,
      },
      error instanceof Error ? error : new Error(String(error))
    );
    throw error;
  }
});
```

### Viewing Test Reports

View pretty-printed test reports using the test:report script:

```bash
npm run test:report <TEST_ID>
```

**Example:**
```bash
npm run test:report GEN-GSDL-001
```

This will display:
- Test status (PASSED/FAILED)
- Test description and metadata
- Input data
- Expected output
- Actual output
- Validation errors and warnings
- Validation summary

If multiple reports exist for the same test ID, the most recent one is shown by default.

### Preparing Tests ("Prep Test")

When asked to "prep test" or "prepare test" with a test ID (e.g., "prep test GEN-GSDL-002"), the following steps must be performed to set up proper test reporting:

1. **Add Test Report Initialization**
   - Add `initTestReport()` call immediately after loading fixtures
   - Include: `testId`, `description`, `input`, `expectedOutput`

2. **Add GraphQL Validation**
   - Replace any commented-out validation with active `expectValidGraphQL()` call
   - Include all required options:
     - `failOnWarnings: false`
     - `expectedFixture: expected`
     - `compareMode: "semantic"`
     - `saveOutput` (conditional on `SAVE_TEST_OUTPUTS` env var)
     - `pluginType` and `pluginName`
     - `testId: TEST_ID`

3. **Add Success Reporting**
   - Wrap validation in try/catch block
   - Call `reportTestPassed()` in the try block with:
     - `testId`, `description`, `input`, `expectedOutput`, `actualOutput`, `validationResult`

4. **Add Error Handling & Failure Reporting**
   - In catch block, call `reportTestFailed()` with:
     - `testId`, `description`, `input`, `expectedOutput`, `actualOutput`, `validationResult`
     - Error object (properly typed)
   - Re-throw the error to fail the test

5. **Add Required Imports**
   - Import `initTestReport`, `reportTestPassed`, `reportTestFailed` from `../helpers/report-test`
   - Import `SchemaCheckResult` type from `../helpers/schema-validator`

**Example Pattern:**
```typescript
it(`[${TEST_ID}] test description`, async () => {
  const input = fixtures.input("input.json") as Grammar;
  const expected = fixtures.expected("expected.graphql");
  
  // Initialize test report context
  initTestReport({
    testId: TEST_ID,
    description: "test description",
    input,
    expectedOutput: expected,
  });
  
  const output = generator.generate(input, options);

  expect(typeof output).toBe("string");
  expect(output.length).toBeGreaterThan(0);

  // REQUIRED: Validate generated GraphQL and compare with expected fixture
  // Validation errors will cause the test to fail and be reported
  let validationResult: SchemaCheckResult | undefined;
  try {
    validationResult = await expectValidGraphQL(output, undefined, {
      failOnWarnings: false,
      expectedFixture: expected,
      compareMode: "semantic",
      saveOutput:
        process.env.SAVE_TEST_OUTPUTS === "true"
          ? "expected.graphql"
          : false,
      pluginType: "generators",
      pluginName: "graphql-sdl",
      testId: TEST_ID,
    });
    
    // Report test passed
    reportTestPassed({
      testId: TEST_ID,
      description: "test description",
      input,
      expectedOutput: expected,
      actualOutput: output,
      validationResult,
    });
  } catch (error) {
    // Report test failed
    reportTestFailed(
      {
        testId: TEST_ID,
        description: "test description",
        input,
        expectedOutput: expected,
        actualOutput: output,
        validationResult,
      },
      error instanceof Error ? error : new Error(String(error))
    );
    throw error;
  }
});
```

**Reference Implementation:**
- See `tests/generators/graphql-sdl.test.ts` test `GEN-GSDL-001` or `GEN-GSDL-002` for complete examples

### Common Testing Activities & Shortcut Phrases

The following activities are commonly performed when working with tests. Use these shortcut phrases to activate them:

#### 1. **Prep Test / Prepare Test**
**Phrase**: `"prep test {TEST_ID}"` or `"prepare test {TEST_ID}"`

**What it does**: Sets up proper test reporting infrastructure for an existing test.

**Activities**:
- Adds `initTestReport()` call with test context
- Adds `expectValidGraphQL()` validation with all required options
- Wraps validation in try/catch with `reportTestPassed()` and `reportTestFailed()`
- Adds required imports (`initTestReport`, `reportTestPassed`, `reportTestFailed`, `SchemaCheckResult`)

**Example**: `"prep test GEN-GSDL-002"` → Prepares test GEN-GSDL-002 with full reporting

---

#### 2. **Create Test**
**Phrase**: `"create test for {description}"` or `"add test for {description}"`

**What it does**: Creates a new test from scratch with fixtures and test code.

**Activities**:
- Creates test ID using `createTestID()` and registers it
- Creates fixture files (input and expected) in appropriate directories
- Writes test code following the test patterns
- Sets up test reporting (calls prep test activities)
- Updates test plan documentation if applicable

**Example**: `"create test for Generate Name in directive context"` → Creates complete test with fixtures

---

#### 3. **Create Fixtures**
**Phrase**: `"create fixtures for {TEST_ID}"` or `"add fixtures for {description}"`

**What it does**: Creates fixture files for a test without creating the test code.

**Activities**:
- Creates input fixture file (JSON for generators, GraphQL for parsers)
- Creates expected fixture file (GraphQL for generators, JSON for parsers)
- Names fixtures using pattern: `{TEST-ID}-{description-kebab-case}.{extension}`
- Places files in correct directory structure (`input/`, `expected/`, `valid/`, `invalid/`)

**Example**: `"create fixtures for GEN-GSDL-007"` → Creates input and expected fixtures

---

#### 4. **Rename Fixtures**
**Phrase**: `"rename fixtures to include test id"` or `"update fixture names"`

**What it does**: Renames existing fixture files to include test ID and description.

**Activities**:
- Renames fixture files to format: `{TEST-ID}-{description-kebab-case}.{extension}`
- Updates all test file references to use new fixture names
- Maintains file extensions and directory structure
- Updates both input and expected fixtures

**Example**: `"rename fixtures to include test id"` → Renames all fixtures and updates references

---

#### 5. **Create Test Plan**
**Phrase**: `"create test plan for {component}"` or `"write test plan"`

**What it does**: Creates a comprehensive test plan document.

**Activities**:
- Creates markdown document with test plan structure
- Organizes tests by grammar sections or component areas
- Includes test IDs, descriptions, and checkboxes for tracking
- Adds test statistics and completion tracking
- Cross-references with existing tests

**Example**: `"create test plan for GraphQL generator"` → Creates comprehensive test plan document

---

#### 6. **View Test Report**
**Phrase**: `"view test report for {TEST_ID}"` or `"show test report {TEST_ID}"`

**What it does**: Displays a test report in human-readable format.

**Activities**:
- Runs `npm run test:report {TEST_ID}`
- Displays test status, input, expected output, actual output
- Shows validation errors and warnings
- Shows test metadata and timestamps

**Example**: `"view test report for GEN-GSDL-001"` → Shows formatted test report

---

#### 7. **Run Test**
**Phrase**: `"run test {TEST_ID}"` or `"test {TEST_ID}"`

**What it does**: Runs a specific test by ID.

**Activities**:
- Executes `npm test -- -t {TEST_ID}`
- Shows test results and output
- Can run multiple tests: `"run tests GEN-GSDL-001 GEN-GSDL-002"`

**Example**: `"run test GEN-GSDL-001"` → Runs specific test

---

#### 8. **Update Test Status**
**Phrase**: `"mark test {TEST_ID} as {status}"` or `"update test status"`

**What it does**: Updates test status in documentation (test plan, status tables).

**Activities**:
- Finds test ID in documentation files
- Updates status indicator (✅ PASSED, ⏳ PENDING, ❌ FAILED, ⏸️ SKIPPED)
- Updates test statistics if applicable
- Updates completion percentages

**Example**: `"mark test GEN-GSDL-001 as PASSED"` → Updates documentation

---

#### 9. **Create Tests from Plan**
**Phrase**: `"create tests from plan"` or `"implement tests from {section}"`

**What it does**: Creates multiple tests based on a test plan section.

**Activities**:
- Reads test plan document
- Creates tests for each planned test ID in the section
- Creates fixtures for each test
- Sets up test reporting for all tests
- Updates test plan with implementation status

**Example**: `"create tests from plan for Name Token section"` → Creates all Name Token tests

---

#### 10. **Fix Test**
**Phrase**: `"fix test {TEST_ID}"` or `"make test {TEST_ID} pass"`

**What it does**: Fixes a failing test.

**Activities**:
- Reads test report to understand failure
- Identifies root cause (generator/parser issue, fixture mismatch, etc.)
- Fixes implementation or updates fixtures as needed
- Validates fix by running test
- Updates test status if successful

**Example**: `"fix test GEN-GSDL-003"` → Fixes failing test

---

#### 11. **List Test IDs**
**Phrase**: `"list test ids"` or `"show all test ids"`

**What it does**: Lists all registered test IDs with their descriptions.

**Activities**:
- Runs `npm run test:ids` or reads test ID registry
- Displays test IDs with descriptions and status
- Shows test file locations
- Can filter by plugin type or pattern

**Example**: `"list test ids"` → Shows all registered test IDs

---

### BTFL Workflow Shortcut

**Phrase**: `"btfl"` or `"run btfl"`

**What it does**: Executes a complete build-test-fix-loop workflow to ensure the project builds successfully and all tests pass.

**Workflow Steps**:

1. **Build the Project**
   - Run `npm run build` (or equivalent build command)
   - Verify the build completes without errors
   - If build fails, proceed to fix errors before continuing

2. **Run the Tests**
   - Execute `npm test -- --run` to run all tests once (non-watch mode)
   - Capture test results and identify any failures

3. **Fix Errors**
   - Analyze test failures and build errors
   - Identify root causes (implementation bugs, fixture mismatches, type errors, etc.)
   - Implement fixes systematically
   - **When encountering key architectural or design decisions:**
     - **Pause and ask the user** for guidance before proceeding
     - **Provide a recommended solution** with rationale
     - **Explain trade-offs** and alternative approaches
     - **Wait for confirmation** before implementing major changes

4. **Loop Back**
   - After fixing errors, return to step 1 (build the project)
   - Continue the cycle until both build and tests pass successfully
   - Only exit the loop when all tests pass and the project builds cleanly

**Key Decision Points** (Always ask before proceeding):
- Changes to public APIs or interfaces
- Modifications to core architecture or plugin system
- Breaking changes to existing functionality
- Significant refactoring that affects multiple files
- Changes to test patterns or validation requirements
- Updates to fixture formats or naming conventions

**Example Usage**: 
- User: `"btfl"` → Agent executes build → runs tests → fixes errors → asks about key decisions → loops back until all pass

**Best Practices**:
- Fix one issue at a time to maintain clarity
- Run tests after each fix to verify the change
- Document any architectural decisions made during the process
- Keep fixes focused and minimal - avoid scope creep

---

### Fixture Naming Convention

**Standard Format**: `{TEST-ID}-{description-kebab-case}.{extension}`

**Examples**:
- Generator input: `GEN-GSDL-001-generates-schema-definition-with-root-operation-types-grammar.json`
- Generator expected: `GEN-GSDL-001-generates-schema-definition-with-root-operation-types-grammar.graphql`
- Parser valid: `PARSE-GSDL-001-parse-name-terminal-with-valid-identifier-pattern.graphql`
- Parser invalid: `PARSE-GSDL-007-parse-name-with-invalid-characters-should-fail.graphql`

**Rules**:
- Always include test ID at the start
- Use kebab-case for descriptions (lowercase, hyphens for spaces)
- Remove special characters, keep only alphanumeric and hyphens
- Include file type indicator (`-grammar` for JSON fixtures, no suffix for GraphQL)
- Maintain consistent naming across input/expected pairs

---

## Code Style

- Use TypeScript strict mode
- Prefer explicit types over `any`
- Use async/await for async operations
- Follow existing patterns for consistency

## Plugin Architecture

- **Parsers**: Convert external formats (e.g., GraphQL SDL) to Grammar
- **Transformers**: Transform Grammar to Grammar
- **Generators**: Convert Grammar to external formats (e.g., JSON, GraphQL SDL)

All plugins are registered in `PluginRegistry` and follow consistent interfaces defined in `src/plugins/types.ts`.

